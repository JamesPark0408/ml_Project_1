{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP30027 Machine Learning, 2022 Semester 1\n",
    "\n",
    "## Assignment 1: Naive Bayes Leaner for Adult Database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Base code [8 marks]\n",
    "\n",
    "Instructions\n",
    "1. Do **not** shuffle the data set\n",
    "2. Treat the attributes as they are(e.g., do **not** convert numeric attributes to categorical or categorical to numeric). Implement a Naive Bayes classifier with appropriate likelihood function for each attribute.\n",
    "3. You should implement the Naive Bayes classifier from scratch. Do **not** use existing implementations/learning algorithms.\n",
    "4. You CANNOT have more than one train or predict function. Both continuous numeric attributes and categorical ones should be trained in one `train()` function, similarly for the `predict()`.  \n",
    "5. Apart from the instructions in point 3, you may use libraries to help you with data reading, representation, maths or evaluation\n",
    "6. Ensure that all and only required information is printed, as indicated in the final three code cells. Failure to adhere to print the required information will result in **[-1 mark]** per case. *(We don't mind details like you print a list or several numbers -- just make sure the information is displayed so that it's easily accessible)\n",
    "7. You may change the prototypes of these functions, and you may write other functions, according to your requirements. We would appreciate it if the required functions were prominent/easy to find. \n",
    "8. You should add adequate comments to make your code easily comprehendible.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T09:06:04.917236Z",
     "start_time": "2022-07-26T09:05:51.933700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries for this project\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import norm \n",
    "from math import log, exp, sqrt, pi\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T09:06:04.929147Z",
     "start_time": "2022-07-26T09:06:04.920768Z"
    }
   },
   "outputs": [],
   "source": [
    "# This function should prepare the data by reading it from a file and converting it into a useful format for training and testing\n",
    "# and implement 90-10 splitting as specified in the project description.\n",
    "\n",
    "def preprocess(filename):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        - filename = path of file to access\n",
    "    \n",
    "    1) Read csv file into a dataframe\n",
    "    2) Split the dataframe into training and testing set (90-10) \n",
    "        (WITHOUT SHUFFLING)\n",
    "    \n",
    "    Return training and test datasets for X and y\n",
    "    \"\"\"\n",
    "    # Reading csv file into dataframe\n",
    "    data = pd.read_csv(filename, sep = ',')\n",
    "    \n",
    "    # Splitting data into 90-10 without shuffling\n",
    "    #     X = attribute values; y = labels \n",
    "    X, y = data.iloc[:,:-1] , data.iloc[:,-1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, shuffle = False)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T09:06:04.943284Z",
     "start_time": "2022-07-26T09:06:04.933895Z"
    }
   },
   "outputs": [],
   "source": [
    "# This function should calculate prior probabilities and likelihoods (conditional probabilities) from the training data and using\n",
    "# to build a naive Bayes model\n",
    "\n",
    "def train(X_train, y_train, num_att, nom_att):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        - X_train = training data of attributes\n",
    "        - y_train = class labels of training data\n",
    "        - num_att = numerical attribute column names\n",
    "        - nom_att = nominal attribute column names\n",
    "    \n",
    "    Using training dataset:\n",
    "    - Compute prior probabilities and conditional probabilities for Naive Bayes model\n",
    "        - Nominal attributes (missing values will be a new category)\n",
    "        - Numeric attributes to fit Gaussian distribution\n",
    "    \n",
    "    Return a dictionary containing:\n",
    "        (FOR CLASS LABELS)\n",
    "        - Probability of class labels\n",
    "            - Key --> class label\n",
    "            - Value --> probability of the class label\n",
    "    \n",
    "        (FOR NOMINAL ATTRIBUTES)\n",
    "        - Conditional probabilities for each value in the nominal attribute(i) and put in dictionary:\n",
    "            - Key --> (attribute, value of attribute, class label)\n",
    "            - Value --> conditional probability of value of attribute given class label\n",
    "        - ***Did Simple Option probability smoothing method where all 0 probabilities were replaced with \n",
    "            an error constant was 0.0000001***\n",
    "        \n",
    "        (FOR NUMERICAL ATTRIBUTES)\n",
    "        - Mean and SD of each numerical attribute(i) and put in dictionary:\n",
    "            - Key --> (attribute, class label, Mean or SD)\n",
    "            - Value --> Mean or SD of attribute containing specific class label\n",
    "    \"\"\"\n",
    "    \n",
    "    # Getting Priors aka class label probabilities\n",
    "    prior_dict = dict(y_train.value_counts(normalize = True))\n",
    "\n",
    "    # Calculate conditional probabilities for nom attributes\n",
    "    nom_dict = nom_probs(pd.concat([X_train[nom_att],y_train], axis = 1))\n",
    "    \n",
    "    # Calculate mean and SD for num attributes\n",
    "    num_dict = num_probs(pd.concat([X_train[num_att],y_train], axis = 1))\n",
    "    \n",
    "    # Add all dictionaries together\n",
    "    NB_dict = {**prior_dict, **nom_dict, **num_dict}\n",
    "    \n",
    "    return NB_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T09:06:04.961462Z",
     "start_time": "2022-07-26T09:06:04.949639Z"
    }
   },
   "outputs": [],
   "source": [
    "def nom_probs(data):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        - data = subset of training data containing only nominal attributes and class label\n",
    "    \n",
    "    Calculate conditional probabilities for each value in the nominal attribute(i) and put in dictionary:\n",
    "        - Key --> (attribute, value of attribute, class label)\n",
    "        - Value --> conditional probability of value of attribute given class label\n",
    "        \n",
    "    To calculate all conditional probabilities, we use NB so we need:\n",
    "        (1) P(class labels)\n",
    "        (2) P(class labels|Atttribute(i)(j))\n",
    "        (3) P(Atttribute(i)(j)) \n",
    "        (*) P(Attr(i)(j)|class label) = P(class label|Attr(i)(j)) * P(Attr(i)(j)) / P(class label)\n",
    "                                    = (2)*(3)/(1)\n",
    "    \n",
    "    Finally, apply Simple Option probability smoothing method where all 0 probabilities were replaced with \n",
    "        an error constant was 0.0000001\n",
    "    \n",
    "    Returns a dictionary containing all conditional probabilities of each value of every attribute given class labels\n",
    "    \"\"\"\n",
    "    LESS_EQ50 = \" <=50K\"\n",
    "    GREATER50 = \" >50K\"\n",
    "    ERROR_CONST = 0.0000001\n",
    "    \n",
    "    # (1) Getting P(class labels): P(\" <=50K\") and P(\" >50K\")\n",
    "    less_eq_50, greater_50 = data[\"label\"].value_counts(normalize = True)\n",
    "    \n",
    "    # Store all required conditional probabilities into dictionary\n",
    "    nom_dict = {}\n",
    "    \n",
    "    # Iterate through every values of each attribute to calculate (2) and (3) \n",
    "    for col in data.iloc[:,:-1]:\n",
    "        attr = data[col]\n",
    "        \n",
    "        # Getting (3) for all values in this attribute in a dictionary format for easy use\n",
    "        val_probs = dict(attr.value_counts(normalize = True))\n",
    "        \n",
    "        # Getting (*) for each attribute value\n",
    "        for value in val_probs.keys():\n",
    "            \n",
    "            # Calculating (2) P(\" <=50K\"|value), P(\" >50K\"|value) and putting them into dict\n",
    "            #     **Account for 0 probabilities for class labels**\n",
    "            p_labels = dict(data[\"label\"].loc[data[col] == value].value_counts(normalize = True))\n",
    "            \n",
    "            # If only 1 key in p_labels --> other class label has to have prob of 0\n",
    "            if(len(p_labels.keys()) == 1):\n",
    "                \n",
    "                # Add 0 for probability of other label which is not included\n",
    "                if(list(p_labels.keys())[0] == LESS_EQ50):\n",
    "                    p_labels[GREATER50] = 0\n",
    "                else:\n",
    "                    p_labels[LESS_EQ50] = 0\n",
    "                    \n",
    "            \n",
    "            \n",
    "            # Now that we have (1),(2), and (3), we can calculate (*) for this attribute\n",
    "            # Calculate P(value| \" <=50\")\n",
    "            p_val_lessEq50 = p_labels[LESS_EQ50] * val_probs[value] / less_eq_50\n",
    "            \n",
    "            # Calculate P(value| \" >50\")\n",
    "            p_val_greater50 = p_labels[GREATER50] * val_probs[value] / greater_50\n",
    "            \n",
    "            # Applying smoothing method\n",
    "            if not p_val_lessEq50:\n",
    "                p_val_lessEq50 = ERROR_CONST\n",
    "            if not p_val_greater50:\n",
    "                p_val_greater50 = ERROR_CONST\n",
    "            \n",
    "            # Add to the dict for collation\n",
    "            nom_dict[(col, value, LESS_EQ50)] = p_val_lessEq50\n",
    "            nom_dict[(col, value, GREATER50)] = p_val_greater50\n",
    "    \n",
    "    return nom_dict\n",
    "        \n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T09:06:04.975986Z",
     "start_time": "2022-07-26T09:06:04.966375Z"
    }
   },
   "outputs": [],
   "source": [
    "def num_probs(data):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        - data = subset of training data containing only numerical attributes and class label\n",
    "    \n",
    "    Calculate Mean and SD of each numerical attribute(i) and put in dictionary:\n",
    "        - Mean and SD of each numerical attribute(i) (ignore missing values)\n",
    "            - Key --> (attribute, class label, Mean or SD)\n",
    "            - Value --> Mean or SD of attribute containing specific class label\n",
    "    \n",
    "    Returns a dictionary of all Mean and SDs of every attribute of a specific class labels\n",
    "    \"\"\"\n",
    "    \n",
    "    LESS_EQ50 = \" <=50K\"\n",
    "    GREATER50 = \" >50K\"\n",
    "    \n",
    "    # Store all required conditional probabilities into dictionary\n",
    "    num_dict = {}\n",
    "    \n",
    "    # Iterate through every attribute to get Mean and SDs\n",
    "    for col in data.iloc[:,:-1]:\n",
    "        attr = data[col]\n",
    "        \n",
    "        # Separate all values in the attribute to specific class label (' <=50K',' >50K')\n",
    "        less_eq_50 = data[col].loc[data[\"label\"] == LESS_EQ50]\n",
    "        greater_50 = data[col].loc[data[\"label\"] == GREATER50]\n",
    "    \n",
    "        # Calculate mean and SD and put it into dictionary\n",
    "        num_dict[(col, LESS_EQ50, \"Mean\")] = less_eq_50.mean()\n",
    "        num_dict[(col, GREATER50, \"Mean\")] = greater_50.mean()\n",
    "        num_dict[(col, LESS_EQ50, \"SD\")] = less_eq_50.std()\n",
    "        num_dict[(col, GREATER50, \"SD\")] = greater_50.std()\n",
    "\n",
    "    return num_dict\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T09:06:04.994852Z",
     "start_time": "2022-07-26T09:06:04.981031Z"
    }
   },
   "outputs": [],
   "source": [
    "# This function should predict classes for new items in the testing data\n",
    "def predict(NB_dict, X_test, num_att, nom_att):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        - NB_dict = dictionary containing all conditional probabilities and priors for NB Classifier calculation\n",
    "        - X_test = testing data of attributes\n",
    "        - num_att = numerical attribute column names\n",
    "        - nom_att = nominal attribute column names\n",
    "    \n",
    "    Using Naive Bayes Classifier, to predict class labels for given X_test \n",
    "    (using Log for probabilities)\n",
    "    \n",
    "    ***We will ignore any missing numerical attributes and any new values in nominal attributes***\n",
    "    (We do not want to skew any results from adding probabilities of new values \n",
    "        as our model did not train for that new value)\n",
    "    \n",
    "    Return 2 lists:\n",
    "        - y_pred = predicted class labels with the row of each value corresponding to same row in X_test\n",
    "        - y_pred_prob = both class label probabilities calculated for y_pred in tuple\n",
    "            - [0] = predicted probability for \" <=50\"\n",
    "            - [1] = predicted probability for \" >50\"\n",
    "    \"\"\"\n",
    "    \n",
    "    LESS_EQ50 = \" <=50K\"\n",
    "    GREATER50 = \" >50K\"\n",
    "    \n",
    "    y_pred = []\n",
    "    y_pred_prob = []\n",
    "\n",
    "    # Iterate every row(instance) and get class labels\n",
    "    for ind in X_test.index:\n",
    "        \n",
    "        # Initialize Conditional probabilities with priors first\n",
    "        pred_p_lessEq50 = NB_dict[LESS_EQ50]\n",
    "        pred_p_greater50 = NB_dict[GREATER50]\n",
    "        \n",
    "        # Go through every nominal attribute and include into probability of each class label\n",
    "        for attr in nom_att:\n",
    "            \n",
    "            # Check if the value is not new\n",
    "            if((attr, X_test[attr][ind], LESS_EQ50) in NB_dict):\n",
    "                \n",
    "                pred_p_lessEq50 *= NB_dict[(attr, X_test[attr][ind], LESS_EQ50)]\n",
    "                pred_p_greater50 *= NB_dict[(attr, X_test[attr][ind], GREATER50)]\n",
    "        \n",
    "        \n",
    "        # Go through every numerical attribute and include into probability of each class label\n",
    "        for attr in num_att:\n",
    "            \n",
    "            # Check if missing value\n",
    "            if(X_test[attr][ind]!= \"?\"):\n",
    "                \n",
    "                pred_p_lessEq50 *= norm(NB_dict[(attr, LESS_EQ50, \"Mean\")]\n",
    "                                        ,NB_dict[(attr, LESS_EQ50, \"SD\")]).pdf(X_test[attr][ind])\n",
    "                pred_p_greater50 *= norm(NB_dict[(attr, GREATER50, \"Mean\")]\n",
    "                                        ,NB_dict[(attr, GREATER50, \"SD\")]).pdf(X_test[attr][ind])\n",
    "        \n",
    "        # Don't forget to log probabilities\n",
    "        pred_p_lessEq50 = log(pred_p_lessEq50)\n",
    "        pred_p_greater50 = log(pred_p_greater50)\n",
    "        \n",
    "        # Pick the highest probability and store it\n",
    "        if(pred_p_lessEq50 > pred_p_greater50):\n",
    "            y_pred.append(LESS_EQ50)\n",
    "\n",
    "        elif(pred_p_lessEq50 < pred_p_greater50):\n",
    "            y_pred.append(GREATER50)\n",
    "\n",
    "        # In case we get same probabilities, we put out both in prediction to say both are equally likely\n",
    "        else:\n",
    "            y_pred.append((LESS_EQ50, GREATER50))\n",
    "        \n",
    "        # Add both probabilities to y_pred_prob\n",
    "        y_pred_prob.append((pred_p_lessEq50, pred_p_greater50))\n",
    "        \n",
    "    return y_pred, y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T09:06:05.008213Z",
     "start_time": "2022-07-26T09:06:04.999301Z"
    }
   },
   "outputs": [],
   "source": [
    "# This function should evaliate the prediction performance by comparing your model’s class outputs to ground\n",
    "# truth labels, return and output accuracy, confusion matrix and F1 score.\n",
    "\n",
    "def evaluate(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Evaluate prediction performance of model (print all results):\n",
    "        - Get confusion matrix(2x2) (Positive --> \" <=50K\"; Negative --> \" >50K\")\n",
    "            - [0][0] = TP\n",
    "            - [0][1] = FN\n",
    "            - [1][0] = FP\n",
    "            - [1][1] = TN\n",
    "        - Get Accuracy --> (TP + TN) / (TP + FP + FN + TN)\n",
    "        - Get F1 score --> 2PR / (P + R)\n",
    "            - P = TP / (TP + FP)\n",
    "            - R = TP / (TP + FN)\n",
    "    \n",
    "    Return Confusion Matrix, Accuracy, F1 score\n",
    "    \"\"\"\n",
    "    \n",
    "    # Getting confusion matrix and printing where:\n",
    "    #     - Positive --> \" <=50K\"\n",
    "    #     - Negative --> \" >50K\"\n",
    "    con_mat = confusion_matrix(y_test, y_pred, labels=[\" <=50K\", \" >50K\"])\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(con_mat)\n",
    "    \n",
    "    # Get tp, fn, fp, tn\n",
    "    tp, fn, fp, tn = con_mat.ravel()\n",
    "    \n",
    "    # Getting Accuracy and printing\n",
    "    accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    \n",
    "    # Getting F1 score\n",
    "    # Get Precision(P)\n",
    "    p = tp / (tp + fp)\n",
    "    \n",
    "    # Get Recall(R)\n",
    "    r = tp / (tp + fn)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1 = 2 * p * r / (p + r)\n",
    "    print(\"F1 score: \", f1)\n",
    "    \n",
    "    return con_mat, accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T09:06:05.662181Z",
     "start_time": "2022-07-26T09:06:05.015851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[69  8]\n",
      " [ 6 17]]\n",
      "Accuracy:  0.86\n",
      "F1 score:  0.9078947368421053\n",
      "Attribute vectors of instances [0, 1, 2]: \n",
      " - Instance[0]:  [68, ' ?', ' 1st-4th', 2, ' Divorced', ' ?', ' Not-in-family', ' White', ' Female', 20, ' United-States'] \n",
      " - Instance[1]:  [39, ' State-gov', ' Bachelors', 13, ' Never-married', ' Adm-clerical', ' Not-in-family', ' White', ' Male', 40, ' United-States'] \n",
      " - Instance[2]:  [50, ' Self-emp-not-inc', ' Bachelors', 13, ' Married-civ-spouse', ' Exec-managerial', ' Husband', ' White', ' Male', 13, ' United-States']\n",
      "\n",
      "Number of instances (N):  1000\n",
      "Number of attributes (F):  11\n",
      "Number of labels (L):  2\n",
      "\n",
      "\n",
      "Predicted class log-probabilities for instance N-3: \n",
      "  <=50:  -20.71689698193305 \n",
      "  >50:  -19.556273652832147\n",
      "Predicted class ID for instance N-3:   >50K\n",
      "\n",
      "Predicted class log-probabilities for instance N-2: \n",
      "  <=50:  -25.33907063773019 \n",
      "  >50:  -22.744589775643142\n",
      "Predicted class ID for instance N-2:   >50K\n",
      "\n",
      "Predicted class log-probabilities for instance N-1: \n",
      "  <=50:  -16.852794958645738 \n",
      "  >50:  -16.716481989445864\n",
      "Predicted class ID for instance N-1:   >50K\n"
     ]
    }
   ],
   "source": [
    "# This cell should act as your \"main\" function where you call the above functions \n",
    "# on the full ADULT data set, and print the evaluation results. [0.33 marks]\n",
    "\n",
    "\n",
    "########################################################################################################\n",
    "# First, read in the data and apply your NB model to the ADULT data\n",
    "\n",
    "# Read data and split into training and testing datasets\n",
    "filename = 'dataset/adult.csv'\n",
    "X_train, X_test, y_train, y_test = preprocess(filename)\n",
    "\n",
    "# Finding numerical and nominal attributes manually\n",
    "num_att = [\"age\", \"education num\", \"hours per week\"]\n",
    "nom_att = X_train.drop(num_att,1).columns.values.tolist()\n",
    "\n",
    "# Training model\n",
    "NB_dict = train(X_train, y_train, num_att, nom_att)\n",
    "\n",
    "# Predicting based on test data\n",
    "y_pred, y_pred_prob = predict(NB_dict, X_test, num_att, nom_att)\n",
    "\n",
    "\n",
    "########################################################################################################\n",
    "# Second, print the full evaluation results from the evaluate() function\n",
    "con_mat, accuracy, f1 = evaluate(y_test, y_pred)\n",
    "\n",
    "\n",
    "########################################################################################################\n",
    "# Third, print data statistics and model predictions, as instructed below \n",
    "# N is the total number of instances, F the total number of attributes, L the total number of labels\n",
    "# The \"class probabilities\" may be unnormalized\n",
    "# The \"predicted class ID\" must be in range (0, L)\n",
    "\n",
    "print(\"Attribute vectors of instances [0, 1, 2]: \\n - Instance[0]: \", list(X_train.iloc[0,:])\n",
    "        , \"\\n - Instance[1]: \", list(X_train.iloc[1,:])\n",
    "        , \"\\n - Instance[2]: \", list(X_train.iloc[2,:]) \n",
    "     ) # of the first three records in adult.csv\n",
    "\n",
    "print(\"\\nNumber of instances (N): \", (len(X_train) + len(X_test)))\n",
    "print(\"Number of attributes (F): \", len(X_train.columns))\n",
    "print(\"Number of labels (L): \", y_train.nunique())\n",
    "\n",
    "\n",
    "# print out the prediction results of the last three instances\n",
    "print(\"\\n\\nPredicted class log-probabilities for instance N-3: \"\n",
    "      + \"\\n \"\" <=50\"\": \", y_pred_prob[-3][0]\n",
    "      , \"\\n \"\" >50\"\": \", y_pred_prob[-3][1]\n",
    "     )\n",
    "print(\"Predicted class ID for instance N-3: \", y_pred[-3])\n",
    "print(\"\\nPredicted class log-probabilities for instance N-2: \"\n",
    "      + \"\\n \"\" <=50\"\": \", y_pred_prob[-2][0]\n",
    "      , \"\\n \"\" >50\"\": \", y_pred_prob[-2][1]\n",
    "     )\n",
    "print(\"Predicted class ID for instance N-2: \", y_pred[-2])\n",
    "print(\"\\nPredicted class log-probabilities for instance N-1: \"\n",
    "      + \"\\n \"\" <=50\"\": \", y_pred_prob[-1][0]\n",
    "      , \"\\n \"\" >50\"\": \", y_pred_prob[-1][1]\n",
    "     )\n",
    "print(\"Predicted class ID for instance N-1: \", y_pred[-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Conceptual questions [8 marks for groups of 1] / [16 marks for groups of 2]\n",
    "\n",
    "\n",
    "If you are in a group of 1, you should respond to Q1 and Q2.\n",
    "\n",
    "If you are in a group of 2, you should respond to Q1, Q2, Q3 and Q4.\n",
    "\n",
    "A response to a question should take about 100–250 words. You may need to develope codes or functions to help respond to the question here. \n",
    "\n",
    "#### NOTE: We strongly recommend <u>including figures or tables, etc.</u> to support your responses. The figures and tables inserted in Markdown cells must be reproducable by your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 [4 marks]\n",
    "<u>Sensitivity</u> and <u>specificity</u> are two model evaluation metrics.  A good model should have both sensitivity and specificity high. Use the $2 \\times 2$ confusion matrix returned by `evaluate()` to calculate the sensitivity and specificity. Do you see a difference between them? If so, what causes this difference? Provide suggestions to improve the model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T09:06:05.670032Z",
     "start_time": "2022-07-26T09:06:05.665789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitivity:  0.8961038961038961\n",
      "specificity:  0.7391304347826086\n"
     ]
    }
   ],
   "source": [
    "# Write additional code here, if necessary (you may insert additional code cells)\n",
    "# Get tp, fn, fp, tn\n",
    "tp, fn, fp, tn = con_mat.ravel()\n",
    "\n",
    "# Getting sensitivity --> TP / (TP + FN)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print(\"sensitivity: \", sensitivity)\n",
    "\n",
    "# Getting specificity --> TN / (TN + FP)\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"specificity: \", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T09:06:05.683057Z",
     "start_time": "2022-07-26T09:06:05.672806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " <=50K    692\n",
       " >50K     208\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is a difference between sensitivity and specificity. The model was able to correctly identify instances where income is less than or equal to 50K better than instances where income is greater than 50K. The difference could be cause due to the fact that the training data were given almost 3.5 time more of \" <=50K\" labeled instances as compared to \" >50K\" labeled instances. \n",
    "\n",
    "To improve the model performance, specifically towards increasing the specificity, we could add more instances labeled \" >50K\" for the training data. \n",
    "\n",
    "As a whole, to improve model performance, instead of assuming all numerical attributes to have a Gaussian distribution, we actually visualize and see the numerical data to check if it follows a Gaussian distribution. For those that do not follow the Gaussian distribution, we can apply KDE instead to those numerical attributes for a more accurate result. \n",
    "\n",
    "We also see that some features are not independent according to our NB assumptions that all features are independent (inductive bias). A clear example would be \"education num\" and \"education\". The values in both attributes are highly correlated = 1. So, before applying NB, we should remove one of the attriubutes to remove as much correlated attributes as we can to fit the assumptions of NB. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 [4 marks]\n",
    "You can adopt different methods for training and/or testing, which will produce different results in model evaluation. \n",
    "\n",
    "(a) Instead of Gaussian, <u>implement KDE</u> for  $P(X_i|c_j)$ for numeric attributes $X_i$. Compare the evaluation results with Gaussian. Which one do you think is more suitable to model $P(X_i|c_j)$, Gaussian or KDE? Observe all numeric attributes and justify your answer.\n",
    "\n",
    "You can choose an arbitrary value for kernel bandwidth $\\sigma$ for KDE, but a value between 3 and 15 is recommended. You should write code to implement KDE, not call an existing function/method such as `KernelDensity` from `scikit-learn`.\n",
    "\n",
    "(b) Implement <u>10-fold and 2-fold cross-validations</u>.  \n",
    "\tObserve the evaluation results in each fold and the average accuracy, recall and specificity over all folds. \n",
    "\tComment on what is the effect by changing the values of $m$ in $m$-fold cross validation. (You can choose either Gaussian or KDE Naive Bayes.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUESTION (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T09:06:05.700941Z",
     "start_time": "2022-07-26T09:06:05.688164Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def predict_KDE(Xy_train, X_test, num_att, nom_att, SD):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        - Xy_train = training data of attributes and labels\n",
    "        - X_test = testing data of attributes\n",
    "        - num_att = numerical attribute column names\n",
    "        - nom_att = nominal attribute column names\n",
    "        - SD = kernal bandwidth chosen \n",
    "    \n",
    "    Using Naive Bayes Classifier, to predict class labels for given X_test \n",
    "    (using Log for probabilities)\n",
    "    \n",
    "    However, for num attributes, we will implement KDE instead of Gaussian\n",
    "        - Done while predicting\n",
    "    \n",
    "    Return a list:\n",
    "        - y_pred = predicted class labels with the row of each value corresponding to same row in X_test\n",
    "    \"\"\"\n",
    "    \n",
    "    # Getting Priors aka class label probabilities\n",
    "    prior_dict = dict(y_train.value_counts(normalize = True))\n",
    "\n",
    "    # Calculate conditional probabilities for nom attributes\n",
    "    nom_dict = nom_probs(pd.concat([X_train[nom_att],y_train], axis = 1))\n",
    "    \n",
    "    # Add all dictionaries together\n",
    "    NB_dict = {**prior_dict, **nom_dict}\n",
    "       \n",
    "        \n",
    "    # Predicting     \n",
    "    LESS_EQ50 = \" <=50K\"\n",
    "    GREATER50 = \" >50K\"\n",
    "    \n",
    "    y_pred = []\n",
    "    n = len(Xy_train)\n",
    "\n",
    "    # Iterate every row(instance) and get class labels\n",
    "    for ind in X_test.index:\n",
    "        \n",
    "        # Initialize Conditional probabilities with priors first\n",
    "        pred_p_lessEq50 = NB_dict[LESS_EQ50]\n",
    "        pred_p_greater50 = NB_dict[GREATER50]\n",
    "        \n",
    "        # Go through every nominal attribute and include into probability of each class label\n",
    "        for attr in nom_att:\n",
    "            # Check if the value is not new\n",
    "            if((attr, X_test[attr][ind], LESS_EQ50) in NB_dict):\n",
    "                pred_p_lessEq50 *= NB_dict[(attr, X_test[attr][ind], LESS_EQ50)]\n",
    "                pred_p_greater50 *= NB_dict[(attr, X_test[attr][ind], GREATER50)]\n",
    "        \n",
    "        # Go through every numerical attribute and implement KDE\n",
    "        for attr in num_att:\n",
    "            x = X_test[attr][ind]\n",
    "            \n",
    "            # Make sure x is not missing (\"?\")\n",
    "            if(x != \"?\"):\n",
    "            \n",
    "                # Separate all values in the attribute to specific class label (' <=50K',' >50K')\n",
    "                less_eq_50 = Xy_train[attr].loc[Xy_train[\"label\"] == LESS_EQ50]\n",
    "                greater_50 = Xy_train[attr].loc[Xy_train[\"label\"] == GREATER50]\n",
    "\n",
    "                # Calculating the KDE for each attribute and class label to be includeded into prediction probability\n",
    "                # For \" <=50\" label\n",
    "                kde = 0\n",
    "                for xi in less_eq_50:\n",
    "                    kde += (1/(SD * sqrt(2 * pi)) * exp(-0.5 * ((x-xi) / SD)**2))\n",
    "                pred_p_lessEq50 *= (kde/n)\n",
    "\n",
    "                # For \" >50\" label\n",
    "                kde = 0\n",
    "                for xi in greater_50:\n",
    "                    kde += (1/(SD * sqrt(2 * pi)) * exp(-0.5 * ((x-xi) / SD)**2))\n",
    "                pred_p_greater50 *= (kde/n)\n",
    "                \n",
    "        # Pick the highest probability and store it\n",
    "        if(pred_p_lessEq50 > pred_p_greater50):\n",
    "            y_pred.append(LESS_EQ50)\n",
    "\n",
    "        elif(pred_p_lessEq50 < pred_p_greater50):\n",
    "            y_pred.append(GREATER50)\n",
    "\n",
    "        # In case we get same probabilities, we put out both in prediction to say both are equally likely\n",
    "        else:\n",
    "            y_pred.append((LESS_EQ50, GREATER50))\n",
    "    \n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T09:06:06.292229Z",
     "start_time": "2022-07-26T09:06:05.705947Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[76  1]\n",
      " [15  8]]\n",
      "Accuracy:  0.84\n",
      "F1 score:  0.9047619047619049\n"
     ]
    }
   ],
   "source": [
    "training_data = pd.concat([X_train, y_train], axis = 1)\n",
    "y_pred_KDE = predict_KDE(training_data, X_test, num_att, nom_att, 3)\n",
    "con_mat_KDE, accuracy_KDE, f1_KDE = evaluate(y_test, y_pred_KDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T09:06:06.927983Z",
     "start_time": "2022-07-26T09:06:06.293886Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fbdf12a0880>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x2160 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting histograms of numerical attributes to visualize and help see which method to use (Gaussian or KDE)\n",
    "\n",
    "# Separating on class labels first\n",
    "LESS_EQ50 = \" <=50K\"\n",
    "GREATER50 = \" >50K\"\n",
    "training_lessEq_50 = (training_data.loc[training_data[\"label\"] == LESS_EQ50])\n",
    "training_greater_50 = (training_data.loc[training_data[\"label\"] == GREATER50])\n",
    "\n",
    "# Initialize plot\n",
    "figure, axis = plt.subplots(3,1)\n",
    "figure.set_size_inches(15,30)\n",
    "\n",
    "# For \"age\" column\n",
    "axis[0].hist(training_lessEq_50[\"age\"], bins = 30, alpha = 0.5, label = \" <=50\")\n",
    "axis[0].hist(training_greater_50[\"age\"], bins = 30, alpha = 0.5, label = \" <=50\")\n",
    "axis[0].set_title(\"age\", fontsize = 40)\n",
    "axis[0].legend(loc = \"upper right\")\n",
    "\n",
    "\n",
    "# For \"education num\" column\n",
    "axis[1].hist(training_lessEq_50[\"education num\"], bins = 14, alpha = 0.5, label = \" <=50\")\n",
    "axis[1].hist(training_greater_50[\"education num\"], bins = 14, alpha = 0.5, label = \" <=50\")\n",
    "axis[1].set_title(\"education num\", fontsize = 40)\n",
    "axis[1].legend(loc = \"upper right\")\n",
    "\n",
    "# For \"hours per week\" column\n",
    "axis[2].hist(training_lessEq_50[\"hours per week\"], bins = 20, alpha = 0.5, label = \" <=50\")\n",
    "axis[2].hist(training_greater_50[\"hours per week\"], bins = 20, alpha = 0.5, label = \" <=50\")\n",
    "axis[2].set_title(\"hours per week\", fontsize = 40)\n",
    "axis[2].legend(loc = \"upper right\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used kernel bandwidth = 3 (3-12 gives same output). We see the model was able to correctly identify instances where income is less than or equal to 50K much better this time but correctly identifying instances where income is greater than 50K deproved. Accuracy dropped by 0.02 and F1 score seems to be almost the same (slightly lower). \n",
    "\n",
    "If our model's goal was more focused towards identifying those with less than or equal to 50K, then this model would be a better option. But since there is no information on the importance on individual labels, our previous model would be the better choice due to better evaluation.\n",
    "\n",
    "Observing the histograms of numerical attributes, we do not see all the distributions to be Gaussian (e.g. \" <=50\" attributes for attribute \"age\" shows a skew to the right). So what would be best is to pick numerical attributes that would fit the Gaussian distribution to use the Gaussian NB while the other numerical attributes use KDE NB. This would be able to make the model performance to increase as now we do not blindly assume distributions for numerical attributes. One way to check for Gaussian distribution is to use scipy normaltest function and depending on the alpha you determine which would test for pvalue signifiance, we can find which attribute fits the Gaussian Distribution or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T13:03:15.146047Z",
     "start_time": "2022-04-05T13:03:15.133471Z"
    }
   },
   "source": [
    "#### QUESTION (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T09:06:06.935518Z",
     "start_time": "2022-07-26T09:06:06.929646Z"
    }
   },
   "outputs": [],
   "source": [
    "def k_fold_evaluation(k, data):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        - k: number of folds\n",
    "        - data: entire dataset \n",
    "        \n",
    "    Steps:\n",
    "    1) Shuffle dataset (ONLY HERE AND NOT DURING ITERATION)\n",
    "    2) Split dataset into 10 folds for each class(groups)\n",
    "    3) Iterate through each fold being the test set while the rest is training set\n",
    "        - Each iteration we will train/test/evaluate (Gaussian NB)\n",
    "        - We want to find accuracy, recall and specificity\n",
    "    4) Average the sum of all the scores we found for respective evaluation metric\n",
    "        - This will give the evaluation score for this cross validation\n",
    "    \n",
    "    Return average accuracy, recall and specificity for k fold\n",
    "    \"\"\"\n",
    "    \n",
    "    # Shuffle dataset (Applied random state to fix the randomization so we can compare results accurately)\n",
    "    #   - \n",
    "    data = shuffle(data, random_state= 55)\n",
    "    data.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    # Set number of folds\n",
    "    fold = KFold(n_splits=k)\n",
    "    \n",
    "    #Variables we want to keep track of\n",
    "    accuracy = 0\n",
    "    recall = 0\n",
    "    specificity = 0\n",
    "    \n",
    "    # Iterate every cross validation of kfolds and evaluate\n",
    "    for train_i, test_i in fold.split(data):\n",
    "        X_train, X_test = data.iloc[train_i,:-1], data.iloc[test_i,:-1]\n",
    "        y_train, y_test = data.iloc[train_i,-1], data.iloc[test_i,-1]\n",
    "        \n",
    "        # Train new model\n",
    "        NB_dict = train(X_train, y_train, num_att, nom_att)\n",
    "        \n",
    "        # Predict with new model\n",
    "        y_pred, y_pred_prob = predict(NB_dict, X_test, num_att, nom_att)\n",
    "        \n",
    "        # Evaluate new model\n",
    "        con_mat, acc, f1 = evaluate(y_test, y_pred)\n",
    "        print('-' * 50)\n",
    "        \n",
    "        # Get accuracy, recall and specificity\n",
    "        accuracy += acc\n",
    "        tp, fn, fp, tn = con_mat.ravel()\n",
    "        recall += tp / (tp + fn)\n",
    "        specificity += tn / (tn + fp)\n",
    "    \n",
    "    # Average out the evaluation scores\n",
    "    accuracy /= k\n",
    "    recall /= k\n",
    "    specificity /= k\n",
    "    \n",
    "    return accuracy, recall, specificity\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T09:06:12.498264Z",
     "start_time": "2022-07-26T09:06:06.937522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[61 14]\n",
      " [ 4 21]]\n",
      "Accuracy:  0.82\n",
      "F1 score:  0.8714285714285714\n",
      "--------------------------------------------------\n",
      "Confusion Matrix:\n",
      "[[65 11]\n",
      " [ 6 18]]\n",
      "Accuracy:  0.83\n",
      "F1 score:  0.8843537414965986\n",
      "--------------------------------------------------\n",
      "Confusion Matrix:\n",
      "[[64 16]\n",
      " [ 6 14]]\n",
      "Accuracy:  0.78\n",
      "F1 score:  0.8533333333333333\n",
      "--------------------------------------------------\n",
      "Confusion Matrix:\n",
      "[[64  7]\n",
      " [10 19]]\n",
      "Accuracy:  0.83\n",
      "F1 score:  0.8827586206896552\n",
      "--------------------------------------------------\n",
      "Confusion Matrix:\n",
      "[[60 17]\n",
      " [ 8 15]]\n",
      "Accuracy:  0.75\n",
      "F1 score:  0.8275862068965517\n",
      "--------------------------------------------------\n",
      "Confusion Matrix:\n",
      "[[69  5]\n",
      " [ 9 17]]\n",
      "Accuracy:  0.86\n",
      "F1 score:  0.9078947368421053\n",
      "--------------------------------------------------\n",
      "Confusion Matrix:\n",
      "[[57 14]\n",
      " [ 8 21]]\n",
      "Accuracy:  0.78\n",
      "F1 score:  0.8382352941176471\n",
      "--------------------------------------------------\n",
      "Confusion Matrix:\n",
      "[[77  9]\n",
      " [ 3 11]]\n",
      "Accuracy:  0.88\n",
      "F1 score:  0.927710843373494\n",
      "--------------------------------------------------\n",
      "Confusion Matrix:\n",
      "[[65 12]\n",
      " [ 6 17]]\n",
      "Accuracy:  0.82\n",
      "F1 score:  0.8783783783783784\n",
      "--------------------------------------------------\n",
      "Confusion Matrix:\n",
      "[[71 11]\n",
      " [ 5 13]]\n",
      "Accuracy:  0.84\n",
      "F1 score:  0.8987341772151899\n",
      "--------------------------------------------------\n",
      "For 10-fold cross validation:\n",
      "Average accuracy:  0.8190000000000002 \n",
      "Average recall:  0.848983339489569 \n",
      "Average specificity:  0.7222397354436335\n"
     ]
    }
   ],
   "source": [
    "# Now we call the function and find out the results\n",
    "\n",
    "# Get the entire dataset as a whole\n",
    "data = pd.read_csv(filename, sep = ',')\n",
    "\n",
    "\n",
    "# Find average accuracy, recall and specificity for 10-fold cross validation\n",
    "accuracy_kfold, recall_kfold, specificity_kfold = k_fold_evaluation(10, data)\n",
    "print(\"For 10-fold cross validation:\\nAverage accuracy: \", accuracy_kfold\n",
    "      , \"\\nAverage recall: \", recall_kfold\n",
    "      , \"\\nAverage specificity: \", specificity_kfold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T09:06:17.024219Z",
     "start_time": "2022-07-26T09:06:12.499919Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[313  66]\n",
      " [ 36  85]]\n",
      "Accuracy:  0.796\n",
      "F1 score:  0.8598901098901099\n",
      "--------------------------------------------------\n",
      "Confusion Matrix:\n",
      "[[336  54]\n",
      " [ 34  76]]\n",
      "Accuracy:  0.824\n",
      "F1 score:  0.8842105263157896\n",
      "--------------------------------------------------\n",
      "For 2-fold cross validation:\n",
      "Average accuracy:  0.81 \n",
      "Average recall:  0.8436979906636899 \n",
      "Average specificity:  0.6966942148760331\n"
     ]
    }
   ],
   "source": [
    "# Find average accuracy, recall and specificity for 2-fold cross validation\n",
    "accuracy_kfold, recall_kfold, specificity_kfold = k_fold_evaluation(2, data)\n",
    "print(\"For 2-fold cross validation:\\nAverage accuracy: \", accuracy_kfold\n",
    "      , \"\\nAverage recall: \", recall_kfold\n",
    "      , \"\\nAverage specificity: \", specificity_kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "We know that, in general, more folds means we have more training data which means we should improve our evaluation, and we see here that the 10-fold does have slightly improved evaluation scores (though it is not significant). Comparing the evaluation metrics, we see that the accuracy is about the same for both kfold, but due to the unbalanced data where there are much more positive case (\" <=50\") instances, this information may not be reliable as the influence of positive case instances would be much higher. We will use accuracy just as a gauge of how well our model is able to get correct responses. More importantly, we will focus on recall and specificity. Recall is the proportion of true positive cases the model was able to detect while specificity is the same but for true negative cases. We see the effect of recall does not change as much due to the large training data there is for positive case. So a split of 2 or 10 would still leave quite a number of data for model to train. The same almost goes for negative cases, however, since it is still much lower than that of positive cases, we would see a bigger drop in specificity when we do 2 fold instead of 10 fold at (~3% in this case)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
